{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path)\n",
    "model['hyper_parameters']['autoencoder_checkpoint'] = '/home/john/PhD/BISCUIT/pretrained_models/AE_gridworld_simplified/AE_40l_64hid.ckpt'\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/miniconda3/envs/biscuit/lib/python3.11/site-packages/pytorch_lightning/utilities/migration/utils.py:55: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.1.0, which is newer than your current Lightning version: v2.0.9.post0\n",
      "  rank_zero_warn(\n",
      "/home/john/miniconda3/envs/biscuit/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from models.biscuit_nf import BISCUITNF\n",
    "import torch\n",
    "from typing import List, Tuple, Dict, Any, Union, Optional\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "autoencoder_path = '/home/john/PhD/BISCUIT/pretrained_moels/AE_gridworld_simplified/AE_20l_64hid.ckpt'\n",
    "model_path = '/home/john/PhD/BISCUIT/pretrained_models/AE_gridworld_simplified/NF_text_only_cardinal.ckpt'\n",
    "model = BISCUITNF.load_from_checkpoint(model_path, autoencoder_path=autoencoder_path)\n",
    "model.to(device)\n",
    "model.freeze()\n",
    "_ = model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "encs_path = '/home/john/PhD/BISCUIT/pretrained_models/AE_gridworld_simplified/encodings/gridworld_simplified_5c_test_indep.pt'\n",
    "encs_path_drop_last_frame = '/home/john/PhD/BISCUIT/pretrained_models/AE_gridworld_simplified/encodings/gridworld_simplified_5c_drop_last_frame_test_indep.pt'\n",
    "t = torch.load(encs_path)\n",
    "t1 = torch.load(encs_path_drop_last_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    img1 = t1[i]\n",
    "    img2 = t[i]\n",
    "    print(img1)\n",
    "    print(img2)\n",
    "    img1 = model.autoencoder.decoder(torch.from_numpy(img1).to(device).unsqueeze(0))\n",
    "    img1 = (img1 + 1) / 2\n",
    "    img2 = model.autoencoder.decoder(torch.from_numpy(img2).to(device).unsqueeze(0))\n",
    "    img2 = (img2 + 1) / 2\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(img1.squeeze().cpu().detach().numpy().transpose(1, 2, 0))\n",
    "    ax[1].imshow(img2.squeeze().cpu().detach().numpy().transpose(1, 2, 0))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = torch.tensor([[ 0.1969,  0.5175, -0.0907, -0.0496,  0.0014,  0.2527, -0.2799, -0.1513,\n",
    "         0.1233,  0.3520,  0.1319,  0.1088, -0.3194,  0.2748, -0.7499, -0.1906,\n",
    "         0.0959,  0.2715,  0.0838, -0.2320]]).to(device)\n",
    "test_image = model.autoencoder.decoder(test_image)\n",
    "test_image = (test_image + 1) / 2\n",
    "plt.imshow(test_image.squeeze().cpu().detach().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_path = '/home/gkounto/BISCUIT/experiments/pretrained_models/AE_gridworld_small/encodings/gridworld_small_pre_intv_freeze_test.pt'\n",
    "encodings = torch.load(encodings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.datasets import GridworldDataset\n",
    "data_folder = '/home/gkounto/BISCUIT/data_generation/data/gridworld_simplified_5c'\n",
    "# val_seq_dataset = GridworldDataset(\n",
    "# data_folder=data_folder, split='val', return_targets=True, return_robot_state=True, single_image=False, triplet=False, seq_len=2, cluster=False, return_text=False, subsample_percentage=0.01)\n",
    "train_seq_dataset = GridworldDataset(\n",
    "        data_folder=data_folder, split='train', return_targets=True, return_latents=True, single_image=False, triplet=False, seq_len=2, cluster=False, return_text=False, subsample_percentage=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from data_generation.gridworld import Gridworld\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def format_causal_dict(causal_dict):\n",
    "    formatted_text = \"\"\n",
    "    for key, value in causal_dict.items():\n",
    "        formatted_text += f\"{key}: {value}\\n\"\n",
    "        if \"position_y\" in key:  # Add a line break after each entity's details\n",
    "            formatted_text += \"\\n\"\n",
    "    return formatted_text\n",
    "\n",
    "def visualize_episode(frames, causals, causal_keys, actions, action_descriptions, interventions):\n",
    "    for i in range(len(frames)):\n",
    "        # debug_causals = Gridworld.causal_vector_to_debug_dict(causal_keys, causals[i])\n",
    "        debug_causals = dict(zip(causal_keys, causals[i]))\n",
    "        formatted_causals = format_causal_dict(debug_causals)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax1 = plt.subplot(1, 2, 1)  # Frame subplot\n",
    "        ax1.imshow(frames[i])\n",
    "        ax1.set_title(f\"Frame {i+1}\")\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2 = plt.subplot(1, 2, 2)  # Textual information subplot\n",
    "        ax2.axis('off')\n",
    "        text_info = (\n",
    "            f\"Step {i+1}:\\n\\n\"\n",
    "            f\"Causals (Formatted):\\n{formatted_causals}\\n\"\n",
    "            f\"Action: {actions[i]}\\n\"\n",
    "            f\"Action Description: {action_descriptions[i]}\\n\"\n",
    "            f\"Interventions: {interventions[i]}\"\n",
    "        )\n",
    "        ax2.text(0, 1, text_info, ha='left', va='top', fontsize=8, wrap=True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "a = np.load('/home/john/PhD/BISCUIT/data_generation/data/gridworld_simplified_18c/check/gridworld_episode_15.npz')\n",
    "causal_keys = json.load(open('/home/john/PhD/BISCUIT/data_generation/data/gridworld_simplified_18c/check_metadata.json'))['flattened_causals']\n",
    "frames, causals, actions, interventions, action_descriptions = a['frames'], a['causals'], a['actions'], a['interventions'], a['action_descriptions']\n",
    "visualize_episode(frames, causals, causal_keys, actions, action_descriptions, interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "# Assume Gridworld, format_causal_dict, and the dataset class are defined elsewhere\n",
    "\n",
    "def visualize_episodes(dataset, causal_keys, N=1):\n",
    "    for episode_idx in range(min(N, len(dataset))):  # Loop through N episodes or the total dataset length\n",
    "        frame_seq = dataset[episode_idx]  # Get the episode data\n",
    "        frames, actions, interventions, causals = frame_seq\n",
    "        \n",
    "        for i in range(frames.shape[0] - 1):  # Iterate through each step, excluding the last frame\n",
    "            # Map causals to keys for the current frame\n",
    "            debug_causals = dict(zip(causal_keys, causals[i]))\n",
    "            formatted_causals = format_causal_dict(debug_causals)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            ax1 = plt.subplot(1, 2, 1)  # Frame subplot\n",
    "            # Adjust image normalization if necessary\n",
    "            img = (frames[i].permute(1, 2, 0).cpu().numpy() + 1.0) / 2.0  # Normalize if required\n",
    "            ax1.imshow(img)\n",
    "            ax1.set_title(f\"Episode {episode_idx + 1}, Frame {i + 1}\")\n",
    "            ax1.axis('off')\n",
    "\n",
    "            ax2 = plt.subplot(1, 2, 2)  # Textual information subplot\n",
    "            ax2.axis('off')\n",
    "            text_info = (\n",
    "                f\"Episode {episode_idx + 1}, Step {i + 1}:\\n\\n\"\n",
    "                f\"Causals (Formatted):\\n{formatted_causals}\\n\"\n",
    "                f\"Action: {actions[i]}\\n\"\n",
    "                f\"Interventions: {interventions[i]}\"\n",
    "            )\n",
    "            ax2.text(0, 1, text_info, ha='left', va='top', fontsize=8, wrap=True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Example usage:\n",
    "causal_keys = json.load(open('/home/gkounto/BISCUIT/data_generation/data/gridworld_simplified/train_metadata.json'))['flattened_causals']\n",
    "# Assuming train_seq_dataset is defined and loaded\n",
    "visualize_episodes(train_seq_dataset, causal_keys, N=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_img(imgs: Any,\n",
    "             figure_title: str = None,\n",
    "             titles: Optional[list] = None):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axes = plt.subplots(1, len(imgs), figsize=(len(imgs) * 3.5, 3.5))\n",
    "    if len(imgs) == 1:\n",
    "        axes = [axes]\n",
    "    for i, ax in enumerate(axes):\n",
    "        if len(imgs[i].shape) == 3 and imgs[i].shape[0] in [3,4]:\n",
    "            imgs[i] = imgs[i].permute(1, 2, 0)\n",
    "        if isinstance(imgs[i], torch.Tensor):\n",
    "            imgs[i] = imgs[i].detach().cpu().numpy()\n",
    "        ax.imshow(imgs[i])\n",
    "        ax.axis('off')\n",
    "        if titles is not None and i < len(titles):\n",
    "            ax.set_title(titles[i], weight='bold')\n",
    "    if figure_title is not None:\n",
    "        fig.suptitle(figure_title, weight='bold', size=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_exclamation_mark_image(size=256, background_color=(1, 1, 1), mark_color=(1, 0, 0), mark_thickness=10, mark_height=100, dot_radius=10):\n",
    "    \"\"\"\n",
    "    Creates an image with a red exclamation mark in the center on a white background.\n",
    "\n",
    "    Parameters:\n",
    "    - size (int): The size of the image (width and height). Default is 256.\n",
    "    - background_color (tuple): The RGB color of the background in the range 0 to 1. Default is white.\n",
    "    - mark_color (tuple): The RGB color of the exclamation mark in the range 0 to 1. Default is red.\n",
    "    - mark_thickness (int): The thickness of the line part of the exclamation mark. Default is 10.\n",
    "    - mark_height (int): The height of the line part of the exclamation mark. Default is 100.\n",
    "    - dot_radius (int): The radius of the dot part of the exclamation mark. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The generated image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Create a size x size x 3 array with the background color\n",
    "    image = np.ones((size, size, 3)) * np.array(background_color)\n",
    "\n",
    "    # Define the center position\n",
    "    center_x, center_y = size // 2, size // 2\n",
    "\n",
    "    # Draw the line part of the exclamation mark\n",
    "    for x in range(center_x - mark_thickness // 2, center_x + mark_thickness // 2):\n",
    "        for y in range(center_y - mark_height // 2, center_y + mark_height // 2 - dot_radius * 2):\n",
    "            image[y, x] = mark_color\n",
    "\n",
    "    # Draw the dot part of the exclamation mark\n",
    "    for x in range(image.shape[1]):\n",
    "        for y in range(image.shape[0]):\n",
    "            if (x - center_x) ** 2 + (y - (center_y + mark_height // 2 + dot_radius)) ** 2 <= dot_radius ** 2:\n",
    "                image[y, x] = mark_color\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def next_step_prediction(\n",
    "        model: BISCUITNF,\n",
    "        image: torch.Tensor,\n",
    "        action: torch.Tensor,\n",
    "        gt_image: torch.Tensor = torch.zeros(1),\n",
    "        latents: Optional[torch.Tensor] = None,\n",
    "        plot_images: bool = True,\n",
    "        intv_targets: Optional[torch.Tensor] = None,\n",
    "        text: Optional[str] = None,\n",
    "        tokenizer: Optional[Any] = None,\n",
    "        text_only: bool = False,\n",
    "        tokenized_description=None,\n",
    "        N: int = 8\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if latents is None:\n",
    "        input_image = (image * 2.0) - 1.0\n",
    "        latents = model.autoencoder.encoder(input_image[None])\n",
    "        latents, _ = model.flow.forward(latents)\n",
    "    # tokenized_description = None\n",
    "    if text is not None:\n",
    "        tokenized_description = tokenizer(text, return_token_type_ids=True, padding='max_length', max_length=64)\n",
    "        input_ids = torch.tensor(tokenized_description['input_ids']).to(device)\n",
    "        token_type_ids = torch.tensor(tokenized_description['token_type_ids']).to(device)\n",
    "        attention_mask = torch.tensor(tokenized_description['attention_mask']).to(device)\n",
    "        tokenized_description = {'input_ids': input_ids, 'token_type_ids': token_type_ids, 'attention_mask': attention_mask}    \n",
    "    new_latents, _ = model.prior_t1.sample(latents, action[None], num_samples=1, intv_targets=intv_targets, tokenized_description=tokenized_description)\n",
    "    new_latents = new_latents.squeeze(1)\n",
    "    new_encodings = model.flow.reverse(new_latents)\n",
    "    new_image = model.autoencoder.decoder(new_encodings)[0]\n",
    "    new_image = (new_image + 1.0) / 2.0\n",
    "    if plot_images:\n",
    "        gt_diff_flag = False\n",
    "        new_image_frame = new_image.permute(1, 2, 0).cpu().numpy()\n",
    "        if latents is None:\n",
    "            old_image_frame = (image.permute(1, 2, 0).cpu().numpy() + 1.0) / 2.0\n",
    "        else:\n",
    "            old_image_frame = image.permute(1, 2, 0).cpu().numpy()\n",
    "        clicked_image_frame = np.copy(old_image_frame)\n",
    "        ground_truth_image_frame = (gt_image.permute(1, 2, 0).cpu().numpy() + 1.0) / 2.0\n",
    "        difference = np.abs(new_image_frame - ground_truth_image_frame)\n",
    "        print(f\"Mean absolute difference between the new image and the ground truth: {difference.mean()}\")\n",
    "        if difference.mean() > 0.001:\n",
    "            print(\"The new image is not close to the ground truth\")\n",
    "            gt_diff_flag = True\n",
    "            exclamation_mark_image = create_exclamation_mark_image()\n",
    "        if action.ndim == 1:\n",
    "            action = action[None]\n",
    "        for i in range(action.shape[0]):\n",
    "            if torch.any(action < 0) or torch.any(action > 1):\n",
    "                continue\n",
    "            # Correct calculation for pixel positions considering the normalized action coordinates\n",
    "            pixel_x = int(action[i, 0].item() * (image.shape[-1] - 1))\n",
    "            pixel_y = int(action[i, 1].item() * (image.shape[-2] - 1))\n",
    "            # Highlight the click location with a red color\n",
    "            clicked_image_frame[max(0, pixel_y-5):pixel_y+6, \n",
    "                                max(0, pixel_x-5):pixel_x+6, \n",
    "                                :] = np.array([1.0, 1.0, 1.0])\n",
    "        if torch.any(gt_image != 0):\n",
    "            image_list = [old_image_frame, clicked_image_frame, new_image_frame, ground_truth_image_frame]\n",
    "            image_titles = ['Previous Frame', 'Click Location', 'New Sample', 'Ground Truth']\n",
    "            if gt_diff_flag:\n",
    "                image_list.append(exclamation_mark_image)\n",
    "                image_titles.append('Difference')\n",
    "            show_img(image_list,\n",
    "                     figure_title=f'Performing action {(action if action.ndim == 1 else action[0]).squeeze().cpu().numpy()}',\n",
    "                     titles=image_titles)\n",
    "        else:\n",
    "            show_img([old_image_frame, clicked_image_frame, new_image_frame],\n",
    "                    figure_title=f'Performing action {(action if action.ndim == 1 else action[0]).squeeze().cpu().numpy()}',\n",
    "                    titles=['Previous Frame', 'Click Location', 'New Sample'])\n",
    "    return new_image, new_latents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = GridworldDataset(\n",
    "\tdata_folder=data_folder, split='val_indep', return_targets=False, single_image=True, return_latents=True, triplet=False, seq_len=2, cluster=False, return_text=False, subsample_percentage=1.0,)\n",
    "for elem in val_dataset:\n",
    "    print(elem[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sequences of train:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "from experiments.datasets import GridworldDataset\n",
    "data_folder = '/home/john/PhD/BISCUIT/data/gridworld_simplified_5c'\n",
    "# val_seq_dataset = GridworldDataset(\n",
    "# data_folder=data_folder, split='val', return_targets=True, return_robot_state=True, single_image=False, triplet=False, seq_len=2, cluster=False, return_text=False, subsample_percentage=0.01)\n",
    "test_seq_dataset = GridworldDataset(\n",
    "        data_folder=data_folder, split='train', return_targets=True, return_latents=True, single_image=False, triplet=False, seq_len=2, cluster=False, return_text=True, subsample_percentage=0.01)\n",
    "val_indep_dataset = GridworldDataset(\n",
    "         data_folder=data_folder, split='val_indep', return_targets=True, single_image=True, return_latents=True, triplet=False, seq_len=1, cluster=False, return_text=True, subsample_percentage=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "test_elem = test_seq_dataset[0]\n",
    "input_ids, token_type_ids, attention_mask = test_elem[-4:-1]\n",
    "tokenizer.decode(input_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def reverseEnum(data: list):\n",
    "    for i in range(len(data)-1, -1, -1):\n",
    "        yield (i, data[i])\n",
    "\n",
    "for i, frame_seq in enumerate(test_seq_dataset):\n",
    "        print(i)\n",
    "        action = torch.tensor(frame_seq[1]).to(device).squeeze()\n",
    "        interventions = torch.tensor(frame_seq[2]).to(device)\n",
    "        causals = torch.tensor(frame_seq[3]).to(device)\n",
    "        tokenized_description = {'input_ids': torch.tensor(frame_seq[3]).to(device), 'token_type_ids': torch.tensor(frame_seq[4]).to(device), 'attention_mask': torch.tensor(frame_seq[5]).to(device)}\n",
    "        print(causals)\n",
    "        print(interventions)\n",
    "        # intv_targets = torch.tensor(frame_seq[2]).to(device)\n",
    "        intv_targets = None\n",
    "        plot_images = True\n",
    "        new_image, new_latents = next_step_prediction(model, frame_seq[0][0], action, gt_image=frame_seq[0][1], plot_images=plot_images, intv_targets=intv_targets, tokenized_description=tokenized_description, text_only=False, N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_dataset[94][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "frame1 = test_seq_dataset[idx][0][0]\n",
    "frame2 = test_seq_dataset[idx][0][1]\n",
    "tokenized_description = {'input_ids': torch.tensor(test_seq_dataset[idx][3]).to(device), 'token_type_ids': torch.tensor(test_seq_dataset[idx][4]).to(device), 'attention_mask': torch.tensor(test_seq_dataset[idx][5]).to(device)}\n",
    "zdt = model.flow(model.autoencoder.encoder(frame1[None]))\n",
    "zdtplus1 = model.flow(model.autoencoder.encoder(frame2[None]))\n",
    "zdtplus1prior = model.prior_t1.sample(zdt[0], action=torch.tensor(test_seq_dataset[94][1]).to(device), num_samples=1, intv_targets=None, tokenized_description=tokenized_description)\n",
    "print(zdt)\n",
    "print(zdtplus1)\n",
    "zdtplus1flow = model.flow.reverse(zdtplus1[0])\n",
    "zdtplus1flow = model.autoencoder.decoder(zdtplus1flow)\n",
    "zdtplus1flow = (zdtplus1flow + 1) / 2\n",
    "zdtplus1prior_ = model.flow.reverse(zdtplus1prior[0])\n",
    "zdtplus1prior_ = model.autoencoder.decoder(zdtplus1prior_)\n",
    "zdtplus1prior_ = (zdtplus1prior_ + 1) / 2\n",
    "from matplotlib import pyplot as plt\n",
    "# plt.imshow(zt.squeeze().cpu().detach().numpy().transpose(1, 2, 0))\n",
    "# plt.imshow(zdtplus1prior_.squeeze().cpu().detach().numpy().transpose(1, 2, 0))\n",
    "plt.imshow(zdtplus1flow.squeeze().cpu().detach().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdtplus1prior[0] - zdtplus1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, frame_seq in enumerate(val_seq_dataset):\n",
    "    # Stack the images at each step to form a sequence\n",
    "    frames, actions = frame_seq\n",
    "    frames = frames.to(device)\n",
    "    actions = torch.from_numpy(actions).to(device)\n",
    "    # interventions = interventions.to(device)\n",
    "    # causals = causals.to(device)\n",
    "    # Perform the next step prediction\n",
    "    new_image, new_latents = next_step_prediction(frames[0], actions, gt_image=frames[1], intv_targets=None, plot_images=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "latents = None\n",
    "image = test_seq_dataset[0][0][0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "load_text = ax.text(image.shape[-1]//2, \n",
    "                image.shape[-2]//2, \n",
    "                'Loading...', \n",
    "                fontsize='x-large',\n",
    "                weight='bold',\n",
    "                va='center',\n",
    "                ha='center',\n",
    "                backgroundcolor=(1.0, 0.8, 0.8))\n",
    "load_text.set_visible(False)\n",
    "ax.axis('off')\n",
    "\n",
    "def onclick(event):\n",
    "    print('click')\n",
    "    global image, latents\n",
    "    load_text.set_visible(True)\n",
    "    fig.canvas.draw()\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    # ix = (ix / image.shape[-1] - 0.5) * 2.0\n",
    "    # iy = (iy / image.shape[-2] - 0.5) * 2.0\n",
    "    print(f'Clicked at x={ix}, y={iy}')\n",
    "    image, latents = next_step_prediction(model, image=image,\n",
    "                                            action=torch.tensor([iy, ix], \n",
    "                                                                    dtype=torch.float32,\n",
    "                                                                    device=device),\n",
    "                                            latents=latents,\n",
    "                                            plot_images=False)\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    load_text.set_visible(False)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_seq_dataset[5][0][0]\n",
    "latents = None\n",
    "action_sequence = [\n",
    "    (0.42857143, 1.),\n",
    "    (0., 0.),\n",
    "    (-0.14285714, -0.14285714),\n",
    "    (0.42857143, 1.),\n",
    "    (0., 0.),\n",
    "]\n",
    "\n",
    "for i, action in enumerate(action_sequence):\n",
    "    image, latents = next_step_prediction(model,\n",
    "                                          image=image, \n",
    "                                          action=torch.tensor(action, device=device), \n",
    "                                          latents=latents,\n",
    "                                          gt_image=test_seq_dataset[5][0][1],\n",
    "                                          plot_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeacf7a64d164d018a1548c39bf7ac42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Action:', placeholder='Type action here'), Button(description='Updaâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47be00f3a5204f1abadcbe8692248b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: You moved the orange boulder left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: You changed the state of the cyan traffic light.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: You changed the state of the silver traffic light.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: You changed the state of the silver traffic light.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# from open_clip import get_tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "# tokenizer = get_tokenizer('hf-hub:timm/ViT-B-16-SigLIP')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "action = torch.tensor((-0.14285714, -0.14285714)).to(device)\n",
    "\n",
    "# Assuming test_seq_dataset, next_step_prediction, and device are defined elsewhere\n",
    "latents = None\n",
    "image = test_seq_dataset[0][0][0]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "load_text = ax.text(image.shape[-1]//2, \n",
    "                    image.shape[-2]//2, \n",
    "                    'Enter action and press \"Update\"', \n",
    "                    fontsize='x-large',\n",
    "                    weight='bold',\n",
    "                    va='center',\n",
    "                    ha='center',\n",
    "                    backgroundcolor=(1.0, 0.8, 0.8))\n",
    "load_text.set_visible(True)  # Initially visible to prompt for input\n",
    "ax.axis('off')\n",
    "\n",
    "# Text input for action\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type action here',\n",
    "    description='Action:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button to trigger the update\n",
    "update_button = widgets.Button(\n",
    "    description='Update',\n",
    "    disabled=False,\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to update based on action',\n",
    "    icon='check'  # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "def on_update_button_clicked(b):\n",
    "    global image, latents\n",
    "    text = text_input.value \n",
    "    \n",
    "    \n",
    "    print(f'Action: {text}') \n",
    "\n",
    "    # Update the image and latents based on the provided action\n",
    "    image, latents = next_step_prediction(model,\n",
    "                                          image=image,\n",
    "                                          action=action,  # Assuming the function now accepts a string\n",
    "                                          latents=latents,\n",
    "                                          plot_images=False,\n",
    "                                          text=text,\n",
    "                                          tokenizer=tokenizer,\n",
    "                                          text_only=True)\n",
    "                                          \n",
    "    \n",
    "    # Update the plot with the new image\n",
    "    ax.clear()  # Clear the previous image\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    load_text.set_visible(False)  # Hide the loading text\n",
    "    ax.axis('off')  # Hide axes again after redrawing\n",
    "    fig.canvas.draw()  # Refresh the figure\n",
    "\n",
    "update_button.on_click(on_update_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "widgets.VBox([text_input, update_button])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prior_t1.text_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You toggled the state of the cyan traffic light'\n",
    "image, latents = next_step_prediction(model,\n",
    "\t\t\t\t\timage=image,\n",
    "\t\t\t\t\taction=torch.tensor(action).to(device),  # Assuming the function now accepts a string\n",
    "\t\t\t\t\tlatents=latents,\n",
    "\t\t\t\t\tplot_images=False,\n",
    "\t\t\t\t\ttext=text,\n",
    "\t\t\t\t\ttokenizer=tokenizer,\n",
    "\t\t\t\t\ttext_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
